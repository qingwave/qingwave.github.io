<!DOCTYPE html><html class=2xl:text-[20px] dir=ltr lang=zh><head><meta charset=UTF-8><meta content="width=device-width,initial-scale=1" name=viewport><title>大模型时代</title><meta content=大模型时代，作为开发者我们该怎么做 name=description><meta content=index,follow name=robots><link href=https://qingwave.github.io/llm-era/ rel=canonical><meta content=大模型时代 property=og:title><meta content=大模型时代，作为开发者我们该怎么做 property=og:description><meta content=https://qingwave.github.io/llm-era/ property=og:url><meta content=article property=og:type><meta content=https://qingwave.github.io/img/blog/llm-levels.png property=og:image><meta content=大模型时代 property=og:image:alt><meta content=summary_large_image name=twitter:card><style is:global>:root{--aw-font-sans:'Inter Variable';--aw-font-serif:var(--aw-font-sans);--aw-font-heading:var(--aw-font-sans);--aw-color-primary:#10b981;--aw-color-secondary:rgb(30 58 138);--aw-color-accent:rgb(109 40 217);--aw-color-text-page:rgb(17 24 39);--aw-color-text-muted:rgb(75 85 99);--aw-color-bg-page:rgb(255 255 255)}</style><meta content=-8bOgP-V4XsxXZtXVx9DIXkdIuruvAYiY37vBg26acI name=google-site-verification><script src="https://www.googletagmanager.com/gtag/js?id=UA-134548083-1" async type=text/partytown></script><script type=text/partytown>(function(){const id = "UA-134548083-1";

  window.dataLayer = window.dataLayer || [];
  function gtag() {
    window.dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", id);
})();</script><link href=/favicon.ico rel="shortcut icon"><link href=/favicon.svg rel=icon type=image/svg+xml><link href=/favicon.svg rel=mask-icon color=#8D46E7><link href=/sitemap-index.xml rel=sitemap><link href=/_astro/_page_.ByvKjQCg.css rel=stylesheet><link href=/_astro/_page_.DUBOU3dI.css rel=stylesheet><script src=/_astro/hoisted.DNuUAAyM.js type=module></script><script>!function(t,e,n,r){(window.crossOriginIsolated||navigator.serviceWorker)&&((r=t[e]=Object.assign(t[e]||{},{lib:"/~partytown/",debug:!1}))[n]=(r[n]||[]).concat(["dataLayer.push"]))}(window,"partytown","forward");const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((()=>{const t=new Set;let e=[];do{Object.getOwnPropertyNames(e).forEach((n=>{"function"==typeof e[n]&&t.add(n)}))}while((e=Object.getPrototypeOf(e))!==Object.prototype);return Array.from(t)})());!function(t,r,o,i,a,s,c,d,l,p,u=t,y){function f(){y||(y=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(l=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(d=setTimeout(h,1e4),r.addEventListener("pt0",b),a?w(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?w():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&w()}))}),console.error):h())))}function w(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.10.2":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function h(n,o){for(b(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<l.length;n++)(o=r.createElement("script")).innerHTML=l[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function b(){clearTimeout(d)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?f():(t.addEventListener("DOMContentLoaded",f),t.addEventListener("load",f))}(window,document,navigator,top,window.crossOriginIsolated),document.addEventListener("astro:before-swap",(t=>{let e=document.body.querySelector("iframe[src*='/~partytown/']");e&&t.newDocument.body.append(e)}))</script></head><body class="dark:text-slate-300 antialiased bg-light dark:bg-dark text-page tracking-tight"><header class="md:py-8 flex-none mt-8 py-4 sticky top-0 w-full z-40" id=header><div class="px-4 mx-auto sm:px-6 max-w-3xl md:flex md:justify-between"><div class="items-center md:flex"><div class="flex justify-between"><a href=/ class="items-center flex"><img alt="" src=/favicon.svg class="h-6 w-6 dark:invert invert-0"></a><div class="items-center flex md:hidden"><button class="items-center dark:text-gray-400 inline-flex p-2.5 text-sm dark:hover:text-slate-300 hover:text-slate-950 text-slate-800" aria-label="Toggle between Dark and Light mode" type=button data-aw-toggle-color-scheme><svg class="h-7 w-7" data-icon=tabler:moon-filled height=1em width=1em><symbol id=ai:tabler:moon-filled viewBox="0 0 24 24"><path d="M12 1.992a10 10 0 1 0 9.236 13.838c.341-.82-.476-1.644-1.298-1.31a6.5 6.5 0 0 1-6.864-10.787l.077-.08c.551-.63.113-1.653-.758-1.653h-.266l-.068-.006z" fill=currentColor /></symbol><use href=#ai:tabler:moon-filled></use></svg></button> <button class="items-center dark:text-gray-400 inline-flex p-2.5 text-sm dark:focus:ring-gray-700 dark:hover:bg-gray-800 focus:outline-none focus:ring-4 focus:ring-gray-200 hover:bg-gray-100 ml-1.5 rounded-lg text-gray-500 transition" aria-label="Toggle Menu" type=button data-aw-toggle-menu><svg class="h-6 w-6" data-icon=tabler:menu height=1em width=1em><symbol id=ai:tabler:menu viewBox="0 0 24 24"><path d="M4 8h16M4 16h16" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:tabler:menu></use></svg></button></div></div><nav aria-label="Main navigation" class="items-center md:flex hidden dark:text-slate-200 h-[calc(100vh-72px)] md:h-auto md:mx-5 md:overflow-visible md:w-auto overflow-y-auto pr-4 w-full"><ul class="flex flex-col md:flex-row md:pt-0 md:self-center md:text-base md:w-auto pt-8 w-full"><li class=""><a href=/blog/ class="items-center flex dark:text-neutral-300 font-medium px-4 py-3 text-neutral-500" memu-item>文章</a></li><li class=""><a href=/project/ class="items-center flex dark:text-neutral-300 font-medium px-4 py-3 text-neutral-500" memu-item>项目</a></li><li class=""><a href=/reading/ class="items-center flex dark:text-neutral-300 font-medium px-4 py-3 text-neutral-500" memu-item>阅读</a></li><li class=""><a href=/about/ class="items-center flex dark:text-neutral-300 font-medium px-4 py-3 text-neutral-500" memu-item>关于我</a></li></ul></nav></div><div class="items-center flex md:mb-0 md:self-center"><div class="items-center md:flex hidden"><button class="items-center dark:text-gray-400 inline-flex p-2.5 text-sm dark:hover:text-slate-300 hover:text-slate-950 text-slate-800" aria-label="Toggle between Dark and Light mode" type=button data-aw-toggle-color-scheme><svg class="h-6 w-6" data-icon=tabler:moon-filled height=1em width=1em viewBox="0 0 24 24"><use href=#ai:tabler:moon-filled></use></svg></button></div></div></div></header><main><section class=page><article><header class=""><div class="flex px-4 flex-col justify-between mb-2 mt-0 mx-auto sm:flex-row sm:items-center sm:px-6"><p class="text-sm dark:text-slate-400 leading-6 text-slatey-700"><time datetime="Wed Aug 07 2024 09:51:22 GMT+0000 (Coordinated Universal Time)">Aug 7, 2024</time> · <a href=/categories/ai/ class="capitalize hover:underline">ai</a></p></div><h1 class="px-4 mx-auto sm:px-6 font-bold font-heading leading-tighter md:text-5xl text-4xl tracking-tighter">大模型时代</h1><p class="px-4 mx-auto sm:px-6 dark:text-slate-400 mb-8 md:text-2xl mt-4 text-justify text-muted text-xl"></p><div class="px-4 mx-auto sm:px-6"><div class="border-t dark:border-slate-700"></div></div></header><div class="mx-auto sm:px-6 px-6 mt-8 3xl:prose-xl break-words dark:prose-a:text-blue-400 dark:prose-headings:text-slate-300 dark:prose-invert overflow-x-hidden prose prose-a:text-primary prose-headings:font-bold prose-headings:font-heading prose-headings:leading-tighter prose-headings:tracking-tighter prose-img:rounded-md prose-img:shadow prose-lg"><p>随着ChatGPT的出圈，基于大模型开发的应用也不断涌现，不管是不是相关方向的从业人员，在这一年多总能听到很多新名词，从<code>LLM</code>、<code>Prompt</code>、<code>RAG</code>到<code>Fine-tuning</code>、<code>Agent</code>，各个大企业都在讲<code>All in AI</code>，一些技术会议也明显感觉到<code>AI</code>占用的篇幅越来越多。</p><p>无论企业还是个人，好像不使用大模型就落伍了，更甚者我们会不会被<code>AI</code>取代，最近听到一种说法挺认同的：</p><blockquote><p>AI不会取代人类，只是会用AI的人会取代不会用的</p></blockquote><p><code>AI</code>或者说大模型是不是正在掀起一场新的工业革命，我不好说，但大模型的影响力比以往近10年产生的新技术都大，譬如区块链、<code>Web3</code>、云原生，所有行业都值得用大模型重新做一遍，上一次有这个待遇的还是互联网，之前常说<code>互联网+</code>，那么现在是不是到了<code>AI+</code>的时代。</p><p>人生又能遇到几次这样的浪潮，在大模型时代，我们要怎么做呢？</p><h2 id=我的大模型之路>我的大模型之路</h2><p>22年12月，ChatGPT横空出世，当时注册卡的很严，借了个账号体验体验，感觉回答的很像真人，比以往所谓的语音助手要好很多，但仅此而已，还没有很深刻的体会。</p><p>23年开始尝试用New Bing来解决工作中遇到的问题，确实比搜索引擎体验好很多。后来趁着出国度假申请了ChatGPT的账号，工作基本是离不开它了，让它来写代码、替代搜索引擎、文章润色。也尝试过其他<code>Github Copilot</code>、<code>LLama3</code>、千问等等，各种LLM发布时号称怎么怎么打败OpenAI，到头来发现还是ChatGPT最好用。</p><p>23年底，公司组织了AI相关的竞赛，借机开始研究怎么基于大模型（LLM）做开发，当时基于<a href=https://github.com/run-llama/llama_index>llama-index</a>开发了一个RAG+自动执行的小应用。后来也开始不断地了解相关知识，<code>LangChain</code>、<code>Agent</code>等。</p><p>接触的越多越发觉得大模型太厉害了，能解决以往不敢想象的事情，虽然还有很多局限性。那么作为开发者，怎么样才能更好地利用大模型呢？</p><h2 id=大模型的能力>大模型的能力</h2><p>如果我们要使用一种技术，必须能清晰地了解这种技术的边界。那么大模型能做什么，不能做什么？</p><p><strong>LLM能做的事</strong></p><ul><li><strong>自然语言的理解和生成</strong>，可以理解并生成文本、代码生成、摘要等</li><li><strong>多语言支持</strong>，在多种语言间进行转换，翻译、代码转换等</li><li><strong>简单的推理</strong>，能够进行一定程度的逻辑推理，如情感识别、问答、修复Bug</li><li><strong>多模态的能力</strong>，识别图像、语言等</li></ul><p><strong>LLM的局限</strong></p><ul><li><strong>幻觉</strong>，倒不如说是大模型的特性，大模型给出的答案可能不准确也不可靠，不能使用的在医疗等准确度要求较高的场景</li><li><strong>推理能力有限</strong>，对于复杂任务效果不好</li><li><strong>深层次的上下文理解</strong>，大模型在需要深层次上下文理解或常识推理的任务中仍会遇到困难</li><li><strong>数据的准确性与时效性</strong>，大模型本身的训练数据可能会含有一些脏数据、政治倾向等，也不包含最新的实时数据</li><li><strong>物理世界的操作</strong>，无法执行外部动作，比如帮你取快递、感知环境</li><li><strong>创造性思维</strong>，虽然大模型能够生成新颖的内容，但内容都是基于训练数据的，并不是真的创新思考</li></ul><p>尽管当前大模型有一些局限，但是随着技术的发展，大模型本身的能力也在不断发展。</p><h2 id=大模型开发>大模型开发</h2><p>我不是专业的LLM开发者，抛开底层的技术和优化（<code>Pre-Training</code>, <code>Fine-Tuning</code>等），基于大模型的应用开发可分为以下几个级别：</p><div style=overflow:auto><table><thead><tr><th>级别</th><th>技术</th><th>解释</th><th>应用</th></tr></thead><tbody><tr><td>L0：无AI</td><td>Code</td><td>根据经验形成代码</td><td>计算器软件，报表系统</td></tr><tr><td>L1：Prompt</td><td>LLM + Prompt</td><td>通过合适提示词得到想要的结果，如Few-Shot、COT</td><td>对话机器人，日报生成，小红书模板</td></tr><tr><td>L2：RAG</td><td>LLM + Prompt + VectorDB</td><td>通过嵌入外部相关数据发送给LLM，得到更准确的回答</td><td>企业问答系统，智能客服</td></tr><tr><td>L3：Workflow</td><td>(LLM + Prompt) * Workflow</td><td>组织多个LLM链实现更复杂的应用，如LangChain Chain</td><td>报表分析、意图识别</td></tr><tr><td>L4：Agent</td><td>LLM + Reflection + Tools + Memory</td><td>智能体可以借助外部工具自动地执行人类布置的多步骤复杂任务，如MetaGPT</td><td>自动故障处理、私人助理</td></tr><tr><td>L5：Autonomous Agents</td><td>Agents + Awareness + Collaboration</td><td>超级智能体可以感知环境，自动做出决策，并可以与其他智能体协作</td><td>斯坦福小镇</td></tr></tbody></table></div><p>类似自动驾驶的分类级别，根据用户参考程度不同，从<code>L0</code>用户全程参与到<code>L5</code>完全不需要用户参与，中间包含有提示词工程Prompt、RAG应用、基于工作流的LLM应用、AI智能体。</p><p><img alt="" src=/img/blog/llm-levels.png loading=lazy></p><p>往靠近底层，实现的功能简单，越往上层自动化程度更高，实现的应用越复杂，上层应用可以使用下层的技术，比如Agent一般都会结合RAG、Prompt等，可以根据自己的需求使用场景，选择合适的应用。</p><h3 id=prompt>Prompt</h3><p><code>Prompt</code>即提示词工程，是指大模型提供的输入提示，用来引导LLM生成特定的输出。通过设计不同的提示，可以控制模型生成的内容和行为。</p><p>通常我们使用大模型的路径如下:</p><pre class="astro-code dracula" data-language=sh style=background-color:#282a36;color:#f8f8f2;overflow-x:auto tabindex=0><code><span class=line><span style=color:#50fa7b>INPUT</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f1fa8c> LLM</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f1fa8c> OUTPUT</span><span style=color:#f1fa8c> +</span><span style=color:#f1fa8c> %</span></span>
<span class=line></span></code></pre><p>提供一个输入，大模型会给出一个带有随机性的输出，怎么样使得这个输出更符合我们的要求呢，那就需要一定技巧的提示词。</p><blockquote><p>不是所有输入都是Prompt，只有携带系统指令的问题才是。比如<code>hi, how are you</code>这不是提示词，而<code>answer my question use chinese, question: 'how are you'</code>包含了指令和问题，其中的前面的指令才算作Prompt。</p></blockquote><p>通过Prompt可以让大模型输出特定的内容，比如生成小红书的爆款文案、返回JSON格式、生成工作日报等等。</p><p><strong>技术</strong></p><p><code>Prompt</code>有很多类型，比如<code>Zero-Shot</code>（无样本提示词）、<code>Few-Shot</code>（少样本提示词）、<code>COT</code>（思维链，可以实现一些较复杂的推理，数学计算等），更多的可以参考<a href=https://www.promptingguide.ai/ >Prompt Engineering</a>。</p><p><strong>示例</strong></p><p>下面是一个简单<code>Few-Shot</code>例子:</p><pre class="astro-code dracula" data-language=yaml style=background-color:#282a36;color:#f8f8f2;overflow-x:auto tabindex=0><code><span class=line><span style=color:#f8f8f2>---</span></span>
<span class=line><span style=color:#8be9fd>Prompt</span><span style=color:#ff79c6>:</span><span style=color:#f1fa8c> 你是一个情感识别专家，根据用户的输入，判断句子是"消极"还是"积极"，下面是一些例子：</span></span>
<span class=line><span style=color:#f1fa8c>这场比赛好极了! // 积极</span></span>
<span class=line><span style=color:#f1fa8c>今天天气热死了 // 消极</span></span>
<span class=line><span style=color:#f1fa8c>这个电影真难看 // 消极</span></span>
<span class=line><span style=color:#f1fa8c>樊振东好样的 //</span></span>
<span class=line><span style=color:#f8f8f2>---</span></span>
<span class=line><span style=color:#8be9fd>LLM</span><span style=color:#ff79c6>:</span><span style=color:#f1fa8c> 积极</span></span>
<span class=line><span style=color:#f8f8f2>---</span></span>
<span class=line></span></code></pre><p><strong>局限</strong></p><ul><li>依赖大模型本身的功能，只能实现相对简单的应用</li><li>基于提示词的应用很难形成壁垒，通过特定手段可以获取到应用的提示词</li></ul><h3 id=rag>RAG</h3><p><code>RAG</code>(Retrieval-Augmented Generation, 检索增强生成)是一种将信息检索与生成模型结合的方法。首先根据用户输入从一个大型文档集合中检索相关信息，然后将用户问题与检索信息发送到大模型，大模型生成对应答案。</p><p><code>RAG</code>可以借助外部知识源，从而提升回答的准确性和信息丰富度，相当于为LLM配置了一个书架，虽然有些知识不知道，但可以参考相关书籍从而获取不错的答案。可以用来做文档问答系统、客服系统、企业内私有数据的问答系统。</p><p><strong>技术</strong></p><p><img alt="" src=/img/blog/llm-rag.jpg loading=lazy></p><p>实现一个基础的<code>RAG</code>应用，如上图所示，一般包含如下步骤：</p><ol><li>将知识库拆分成固定大小的块</li><li>选择合适的<code>Embedding</code>模型将数据块向量化，存放在VectorDB(向量数据库)中</li><li>用户查询时，在VectorDB中匹配相关内容</li><li>将用户输入与检索信息发送给大模型</li><li>大模型整理后返回结果</li></ol><p>图中也展示一些知识来提升<code>RAG</code>的效果，比如：</p><ul><li>混合搜索，通过多路召回，综合VectorDB、DB与其他数据源中的数据以提升回答的准确性</li><li>数据清洗，<code>RAG</code>应用的效果依赖于高质量的数据</li><li>效果评估，引入评估系统</li></ul><p>借助<code>llama-index</code>与<code>LangChain</code>等工具，可以方便地实现<code>RAG</code>应用。</p><p><strong>与Fine-tuning的区别</strong></p><p>在使用中，<code>RAG</code>经常会与<code>Fine-tuning</code>（微调）做比较。</p><ul><li><code>RAG</code>可以借助外部数据集，通过检索数据发送给大模型以提升回答效果，大模型本身不知道这些外部知识。<code>RAG</code>成本更低，适合频繁更新的场景，新闻摘要、实时回答等。</li><li><code>Fine-tuning</code>是在较小的数据集上继续训练大模型，使其参数更好地适应任务需求。有助于模型理解任务的细微差别，通常用于情感分析、法律文档分析和医学报告生成等需要特定领域术语和风格的任务。微调的上限更高，成本也更高，但不适合频繁更新数据的场景。</li></ul><p>两者并不互斥，可以结合一起以实现更好的效果。</p><p><strong>局限</strong></p><ul><li>检索相关性，检索的相关性直接影响最终的效果，通过向量检索来匹配<code>TopK</code>内容，比如问<code>你吃了吗</code>，正确的应该是去搜索<code>我吃了...</code>而不是直接搜索问题</li><li>汇总信息，无法进行对比和汇总，比如<em>分析近10天关于AI的新闻</em></li><li>Token限制，每个LLM都有Token数限制，一些长上下文可能无法全量发送给LLM</li></ul><h3 id=workflow>Workflow</h3><p>对于一些复杂任务，LLM并不能很好处理，可以将这些任务拆分成多个步骤，每个步骤使用LLM实现一个简单的任务，将这些任务串起来便是<code>Workflow</code>。</p><p>比如可以实现一个歌词应用，拆分为作词与评论，作词链只负责作词，根据用户输入输出对应的歌词；评论家负责评论歌词内容提出建议。</p><pre class="astro-code dracula" data-language=sh style=background-color:#282a36;color:#f8f8f2;overflow-x:auto tabindex=0><code><span class=line><span style=color:#50fa7b>INPUT</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f8f8f2> [LYRICIST </span><span style=color:#f1fa8c>CHAIN</span><span style=color:#f8f8f2>(</span><span style=color:#50fa7b>LLM</span><span style=color:#f8f8f2>) </span><span style=color:#f1fa8c>]</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f1fa8c> LYRIC</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f8f8f2> [REVIEWER </span><span style=color:#f1fa8c>CHAIN</span><span style=color:#f8f8f2>(</span><span style=color:#50fa7b>LLM</span><span style=color:#f8f8f2>)</span><span style=color:#f1fa8c>]</span><span style=color:#f8f8f2> -</span><span style=color:#ff79c6>></span><span style=color:#f1fa8c> OUTPUT</span></span>
<span class=line></span></code></pre><p><strong>技术</strong></p><p><code>Workflow</code>是将复杂任务分解为更小的、可管理的单元，结合LLM实现一个多步骤的复杂任务。可以是链式的、或者更复杂的有向无环图。比如<code>LangChain</code>的名字本身就指的是大模型链，其中的<code>SimpleSequentialChain</code>就是顺序调用链、<code>RouterChain</code>路由链，可以动态选择下一个路径形成更复杂的工作流。</p><p><strong>局限</strong></p><ul><li>工作流的调用关系在代码中是写死的，无法灵活处理，只适合特定任务</li><li>误差累积，初期步骤的错误可能导致执行失败</li><li>上下文丢失，链条过长造成上下文模糊甚至丢失</li></ul><h3 id=agent>Agent</h3><p><code>Agent</code>本意是代理人，比如房屋中介，能代替人做部分事情。具体到<code>LLM Agent</code>目前没有一个统一的定义，常翻译为智能体，通常指能够能够感知环境、进行决策并执行动作的智能实体。</p><p><strong>技术</strong></p><p>下图是一个<code>Agent</code>认可较广的架构，来源于OPENAI的<a href=https://lilianweng.github.io/ >lilianweng</a>： <img alt="" src=/img/blog/llm-agent.png loading=lazy></p><p><code>Agent</code>可以用公式定义为：</p><pre class="astro-code dracula" data-language=sh style=background-color:#282a36;color:#f8f8f2;overflow-x:auto tabindex=0><code><span class=line><span style=color:#50fa7b>Agent</span><span style=color:#f1fa8c> =</span><span style=color:#f1fa8c> LLM</span><span style=color:#f1fa8c> +</span><span style=color:#f1fa8c> Planning</span><span style=color:#f1fa8c> +</span><span style=color:#f1fa8c> Action</span><span style=color:#f1fa8c> +</span><span style=color:#f1fa8c> Tools</span><span style=color:#f1fa8c> +</span><span style=color:#f1fa8c> Memory</span></span>
<span class=line></span></code></pre><p>智能体能够实现复杂任务的规划，可以借助外部工具执行每一个步骤，根据执行结果不断调整，并将结果记录存储起来，最终完成任务。拆开来看：</p><ul><li>LLM：LLM作为智能体的<strong>大脑</strong>，可以实现任务的规划、根据执行结果进行反思。</li><li>Tools：由于LLM本身的局限，借助外部工具赋予智能体<strong>双手</strong>，可以根据任务步骤做出行动，如查询天气、执行代码、搜索内容。</li><li>Memory：智能体可以<strong>记忆</strong>过去的经验，这对学习至关重要，可以根据这些先前的经验调整未来的行动。</li></ul><p>借助智能体我们可以实现更加智能化、多步骤的任务，相比<code>Workflow</code>具体的执行流是由LLM制定的，并不是人类经验的硬编码。使用<code>Agent</code>可以实现数据分析、智能个人助手、自动运维工具等。</p><p>更进一步多智能体（<code>Multi-Agent</code>）可以视为一个智能社会，不同<code>Agent</code>分工协作实现更加复杂的场景，例如一个软件公司包括<strong>产品经理 / 架构师 / 项目经理 / 工程师</strong>多个智能体，一起协作来实现复杂的软件。当前也有一些多智能体的框架，如<code>MetaGPT</code>、<code>LangGraph</code>等。</p><p><strong>局限</strong></p><ul><li>依赖LLM，<code>Agent</code>的推理、反思、规划能力都依赖大模型，不同模型效果有差异</li><li>很难脱离人类单独运行，一些危险操作（修改数据），无法保证<code>Agent</code>的精确性，需要人类参与</li><li>复杂性，实现更复杂，尤其是多智能体，很难测试验证</li></ul><h2 id=总结>总结</h2><p>大模型时代，作为开发者我们可以借助大模型的能力实现更加智能的应用，本文介绍了多个大模型的开发级别，从简单的提示词到智能体，每一个级别都有其特点和局限，选择合适的技术来适配不同场景，你也可以转化为一个AI加持的开发者。</p><p>展望一下未来，随着AI技术的发展，真正的智能有没有可能实现呢？各种智能体可以替代我们做事，甚至做一些人类做不到的事情。</p><h2 id=引用>引用</h2><ul><li><a href=https://arxiv.org/html/2401.05459v1>https://arxiv.org/html/2401.05459v1</a></li><li><a href=https://www.promptingguide.ai/ >https://www.promptingguide.ai/</a></li><li><a href=https://substack.com/@cwolferesearch/note/c-48888444>https://substack.com/@cwolferesearch/note/c-48888444</a></li><li><a href=https://lilianweng.github.io/posts/2023-06-23-agent/ >https://lilianweng.github.io/posts/2023-06-23-agent/</a></li><li><a href=https://docs.deepwisdom.ai/ >https://docs.deepwisdom.ai/</a></li><li><a href=https://python.langchain.com/ >https://python.langchain.com/</a></li></ul><blockquote><p>Explore more in <a href=https://qingwave.github.io>https://qingwave.github.io</a></p></blockquote></div><div class="flex flex-col justify-between mx-auto sm:flex-row sm:px-6 mt-8 px-6"><ul class=mr-5><li class="rounded-full border border-slate-500 dark:border-slate-100 font-medium inline-block mx-1 my-1 px-2 py-1"><a href=/tags/ai/ class="dark:text-slate-300 dark:hover:text-blue-400 hover:text-primary text-muted">#ai</a></li></ul></div></article><div class="mx-auto sm:px-6 px-6 dark:text-slate-400 giscus-container py-16 text-muted"><script src=https://giscus.app/client.js async crossorigin=anonymous data-category=Announcements data-category-id=DIC_kwDOCg97r84CBQfL data-emit-metadata=0 data-input-position=top data-lang=en data-loading=lazy data-mapping=title data-reactions-enabled=1 data-repo=qingwave/qingwave.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNjg3ODY4NjM=" data-strict=0 data-theme=light></script></div></section><div class="bottom-8 fixed hidden right-6 z-50" id=back-to-top><button class="rounded-full dark:hover:bg-slate-800 dark:hover:text-gray-100 dark:text-gray-300 hover:bg-neutral-100 hover:text-neutral-500 p-3 text-neutral-300"><svg class="h-6 w-6" data-icon=ph:rocket-fill height=1em width=1em><symbol id=ai:ph:rocket-fill viewBox="0 0 256 256"><path d="M152 224a8 8 0 0 1-8 8h-32a8 8 0 0 1 0-16h32a8 8 0 0 1 8 8m71.62-68.17l-12.36 55.63a16 16 0 0 1-25.51 9.11L158.51 200h-61l-27.26 20.57a16 16 0 0 1-25.51-9.11l-12.36-55.63a16.09 16.09 0 0 1 3.32-13.71l28.56-34.26a123 123 0 0 1 8.57-36.67c12.9-32.34 36-52.63 45.37-59.85a16 16 0 0 1 19.6 0c9.34 7.22 32.47 27.51 45.37 59.85a123 123 0 0 1 8.57 36.67l28.56 34.26a16.09 16.09 0 0 1 3.32 13.71m-139.23 34q-16.11-29.33-19.56-57.67L48 152.36L60.36 208l.18-.13ZM140 100a12 12 0 1 0-12 12a12 12 0 0 0 12-12m68 52.36l-16.83-20.2q-3.42 28.28-19.56 57.69l23.85 18l.18.13Z" fill=currentColor /></symbol><use href=#ai:ph:rocket-fill></use></svg></button></div></main><footer class=relative><div class="px-4 mx-auto sm:px-6 max-w-3xl"><div class="border-t border-gray-200 dark:border-slate-800"></div></div><div class="dark:bg-dark absolute inset-0 pointer-events-none" aria-hidden=true></div><div class="px-4 mx-auto sm:px-6 max-w-3xl dark:text-slate-300 relative"><div class="md:flex md:justify-between md:items-center md:py-8 py-6"><ul class="md:flex hidden -ml-2 mb-4 md:mb-0 md:ml-4 md:order-1"><li><a href=/rss.xml class="items-center dark:text-gray-400 inline-flex p-2.5 text-sm text-muted" aria-label=RSS><svg class="h-5 w-5" data-icon=tabler:rss height=1em width=1em><symbol id=ai:tabler:rss viewBox="0 0 24 24"><path d="M4 19a1 1 0 1 0 2 0a1 1 0 1 0-2 0M4 4a16 16 0 0 1 16 16M4 11a9 9 0 0 1 9 9" fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 /></symbol><use href=#ai:tabler:rss></use></svg></a></li></ul><div class="text-sm dark:text-slate-400 mr-4"><span class="h-5 w-5 bg-[url(/favicon.ico)] bg-cover float-left md:-mt-0.5 mr-1.5 rounded-sm"></span> <span class="dark:text-slate-300 text-slate-700"><a href=https://qingwave.github.io class=hover:brightness-50>Qingwave</a> · All rights reserved.</span></div></div></div></footer><script>!function(){const e="light";function t(e){"dark"===e?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")}function o(e,t,o){const n="string"==typeof e?document.querySelectorAll(e):e;n&&n.length&&n.forEach((e=>{e.addEventListener(t,(t=>o(t,e)),!1)}))}e&&e.endsWith(":only")||!localStorage.theme?t(e.replace(":only","")):"dark"===localStorage.theme||!("theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):t("light"),window.onload=function(){let t=window.scrollY,n=!0;function c(){const e=document.getElementById("header");t>60&&!e.classList.contains("scroll")?document.getElementById("header").classList.add("scroll"):t<=60&&e.classList.contains("scroll")&&document.getElementById("header").classList.remove("scroll"),n=!1}o("[data-aw-toggle-menu]","click",(function(e,t){t.classList.toggle("expanded"),document.body.classList.toggle("overflow-hidden"),document.getElementById("header")?.classList.toggle("h-screen"),document.querySelector("#header nav")?.classList.toggle("hidden")})),o("[data-aw-toggle-color-scheme]","click",(function(){e.endsWith(":only")||(document.documentElement.classList.toggle("dark"),localStorage.theme=document.documentElement.classList.contains("dark")?"dark":"light",function(e){const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")}({setConfig:{theme:localStorage.theme}}))})),o("[data-aw-social-share]","click",(function(e,t){const o=t.getAttribute("data-aw-social-share"),n=encodeURIComponent(t.getAttribute("data-aw-url")),c=encodeURIComponent(t.getAttribute("data-aw-text"));let a;switch(o){case"facebook":a=`https://www.facebook.com/sharer.php?u=${n}`;break;case"twitter":a=`https://twitter.com/intent/tweet?url=${n}&text=${c}`;break;case"linkedin":a=`https://www.linkedin.com/shareArticle?mini=true&url=${n}&title=${c}`;break;case"whatsapp":a=`https://wa.me/?text=${c}%20${n}`;break;case"mail":a=`mailto:?subject=%22${c}%22&body=${c}%20${n}`;break;default:return}const s=document.createElement("a");s.target="_blank",s.href=a,s.click()})),c(),o([document],"scroll",(function(){t=window.scrollY,n||(window.requestAnimationFrame((()=>{c()})),n=!0)}))},window.onpageshow=function(){document.documentElement.classList.add("motion-safe:scroll-smooth");const e=document.querySelector("[data-aw-toggle-menu]");e&&e.classList.remove("expanded"),document.body.classList.remove("overflow-hidden"),document.getElementById("header")?.classList.remove("h-screen"),document.querySelector("#header nav")?.classList.add("hidden")}}()</script></body></html>